{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19120,"status":"ok","timestamp":1757788340713,"user":{"displayName":"asap","userId":"06484538537065995243"},"user_tz":-540},"id":"x2JjLZhdU18b","outputId":"dc089fdb-daf2-49a6-8498-8ec02ab7ac03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive, userdata\n","import os\n","import sys\n","\n","drive.mount('/content/drive')\n","userdata.get('HF_TOKEN')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67349,"status":"ok","timestamp":1757788408063,"user":{"displayName":"asap","userId":"06484538537065995243"},"user_tz":-540},"id":"M9YPdYKlU18c","outputId":"c548f830-3f2b-4e98-fee0-f82298d0fba8"},"outputs":[{"name":"stdout","output_type":"stream","text":["依存関係をインストール中...\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Flash Attention がインストールされました\n"]}],"source":["!pip install transformers>=4.21.0 --quiet\n","!pip install torch torchvision torchaudio --quiet\n","!pip install tqdm --quiet\n","!pip install datasets --quiet\n","!pip install datatrove --quiet\n","\n","try:\n","    !pip install flash-attn --no-build-isolation --quiet\n","    print(\"Flash Attention がインストールされました\")\n","except:\n","    print(\"Flash Attention のインストールに失敗 - 標準Attentionを使用します\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1757788408395,"user":{"displayName":"asap","userId":"06484538537065995243"},"user_tz":-540},"id":"3A8_-fJ-U18c","outputId":"6eb765ca-346c-49fb-a34d-3d76bc0254c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["作業ディレクトリ: /content/drive/MyDrive/LightLM-main\n"]}],"source":["#Google Drive内のモジュールを利用するために作業ディレクトリを変更し、pathに追加する\n","lightlm_path = '/content/drive/MyDrive/LightLM'\n","\n","os.chdir(lightlm_path)\n","print(f\"作業ディレクトリ: {os.getcwd()}\")\n","\n","if lightlm_path not in sys.path:\n","    sys.path.insert(0, lightlm_path)"]},{"cell_type":"code","source":["# デフォルトのチェックポイントパス（train.pyから）\n","default_checkpoint = lightlm_path + \"/model_testing/model.checkpoint.epoch0_step23500_global23500.pt\"\n","model_dir = lightlm_path + \"/hf_model\"\n","repo_name = \"user/repo\"\n","private = False"],"metadata":{"id":"ojaLO_PJKHVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zOg82OBZJZQ"},"outputs":[],"source":["#モデルのコンバートを実施する\n","import os\n","import torch\n","import json\n","import shutil\n","from transformers import AutoTokenizer\n","from model import Transformer, ModelConfig\n","from convert_to_hf import convert_checkpoint_to_hf\n","\n","if not os.path.exists(default_checkpoint):\n","    print(f\"❌ Checkpoint not found: {default_checkpoint}\")\n","    print(\"Available checkpoints:\")\n","    checkpoint_dir = lightlm_path + \"/model_testing\"\n","    if os.path.exists(checkpoint_dir):\n","        for file in os.listdir(checkpoint_dir):\n","            if file.endswith('.pt'):\n","                print(f\"   - {os.path.join(checkpoint_dir, file)}\")\n","\n","\n","print(f\"🚀 Converting checkpoint to HuggingFace format...\")\n","output_dir = convert_checkpoint_to_hf(default_checkpoint)\n","print(f\"🎉 Done! Model is ready for upload to HuggingFace Hub.\")\n","print(f\"    Next step: Run 'python upload_to_hub.py' to upload to HuggingFace\")"]},{"cell_type":"code","source":["import os\n","import json\n","from transformers import AutoTokenizer\n","from huggingface_hub import HfApi\n","from upload_to_hub import upload_to_huggingface\n","\n","token = os.getenv('HF_TOKEN')\n","\n","try:\n","    url = upload_to_huggingface(\n","        model_dir=model_dir,\n","        repo_name=repo_name,\n","        private=private,\n","        token=token\n","    )\n","    print(f\"🎉 Success! Your model is now available at: {url}\")\n","\n","except Exception as e:\n","    print(f\"❌ Upload failed: {e}\")\n","    print(\"   Make sure you have:\")\n","    print(\"   1. Valid HuggingFace token\")\n","    print(\"   2. Proper permissions\")\n","    print(\"   3. Unique repository name\")"],"metadata":{"id":"N3iQrQwgHcK4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}