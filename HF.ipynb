{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19120,"status":"ok","timestamp":1757788340713,"user":{"displayName":"asap","userId":"06484538537065995243"},"user_tz":-540},"id":"x2JjLZhdU18b","outputId":"dc089fdb-daf2-49a6-8498-8ec02ab7ac03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive, userdata\n","import os\n","import sys\n","\n","drive.mount('/content/drive')\n","userdata.get('HF_TOKEN')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67349,"status":"ok","timestamp":1757788408063,"user":{"displayName":"asap","userId":"06484538537065995243"},"user_tz":-540},"id":"M9YPdYKlU18c","outputId":"c548f830-3f2b-4e98-fee0-f82298d0fba8"},"outputs":[{"name":"stdout","output_type":"stream","text":["ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Flash Attention ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã—ãŸ\n"]}],"source":["!pip install transformers>=4.21.0 --quiet\n","!pip install torch torchvision torchaudio --quiet\n","!pip install tqdm --quiet\n","!pip install datasets --quiet\n","!pip install datatrove --quiet\n","\n","try:\n","    !pip install flash-attn --no-build-isolation --quiet\n","    print(\"Flash Attention ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã—ãŸ\")\n","except:\n","    print(\"Flash Attention ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•— - æ¨™æº–Attentionã‚’ä½¿ç”¨ã—ã¾ã™\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1757788408395,"user":{"displayName":"asap","userId":"06484538537065995243"},"user_tz":-540},"id":"3A8_-fJ-U18c","outputId":"6eb765ca-346c-49fb-a34d-3d76bc0254c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: /content/drive/MyDrive/LightLM-main\n"]}],"source":["#Google Driveå†…ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã«ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å¤‰æ›´ã—ã€pathã«è¿½åŠ ã™ã‚‹\n","lightlm_path = '/content/drive/MyDrive/LightLM'\n","\n","os.chdir(lightlm_path)\n","print(f\"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}\")\n","\n","if lightlm_path not in sys.path:\n","    sys.path.insert(0, lightlm_path)"]},{"cell_type":"code","source":["# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹ï¼ˆtrain.pyã‹ã‚‰ï¼‰\n","default_checkpoint = lightlm_path + \"/model_testing/model.checkpoint.epoch0_step23500_global23500.pt\"\n","model_dir = lightlm_path + \"/hf_model\"\n","repo_name = \"user/repo\"\n","private = False"],"metadata":{"id":"ojaLO_PJKHVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zOg82OBZJZQ"},"outputs":[],"source":["#ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒãƒ¼ãƒˆã‚’å®Ÿæ–½ã™ã‚‹\n","import os\n","import torch\n","import json\n","import shutil\n","from transformers import AutoTokenizer\n","from model import Transformer, ModelConfig\n","from convert_to_hf import convert_checkpoint_to_hf\n","\n","if not os.path.exists(default_checkpoint):\n","    print(f\"âŒ Checkpoint not found: {default_checkpoint}\")\n","    print(\"Available checkpoints:\")\n","    checkpoint_dir = lightlm_path + \"/model_testing\"\n","    if os.path.exists(checkpoint_dir):\n","        for file in os.listdir(checkpoint_dir):\n","            if file.endswith('.pt'):\n","                print(f\"   - {os.path.join(checkpoint_dir, file)}\")\n","\n","\n","print(f\"ğŸš€ Converting checkpoint to HuggingFace format...\")\n","output_dir = convert_checkpoint_to_hf(default_checkpoint)\n","print(f\"ğŸ‰ Done! Model is ready for upload to HuggingFace Hub.\")\n","print(f\"    Next step: Run 'python upload_to_hub.py' to upload to HuggingFace\")"]},{"cell_type":"code","source":["import os\n","import json\n","from transformers import AutoTokenizer\n","from huggingface_hub import HfApi\n","from upload_to_hub import upload_to_huggingface\n","\n","token = os.getenv('HF_TOKEN')\n","\n","try:\n","    url = upload_to_huggingface(\n","        model_dir=model_dir,\n","        repo_name=repo_name,\n","        private=private,\n","        token=token\n","    )\n","    print(f\"ğŸ‰ Success! Your model is now available at: {url}\")\n","\n","except Exception as e:\n","    print(f\"âŒ Upload failed: {e}\")\n","    print(\"   Make sure you have:\")\n","    print(\"   1. Valid HuggingFace token\")\n","    print(\"   2. Proper permissions\")\n","    print(\"   3. Unique repository name\")"],"metadata":{"id":"N3iQrQwgHcK4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}